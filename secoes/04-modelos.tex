\section{Modelos de LLMs avaliados}
\subsection{ChatGPT}
A família de modelos GPT (\textit{Generative Pre-trained Transformer}), desenvolvida pela OpenAI, é um dos exemplos mais conhecidos e amplamente utilizados de \textit{Large Language Models} (LLMs). Baseados em arquiteturas de transformadores, esses modelos são pré-treinados em grandes volumes de dados textuais de forma não supervisionada, adquirindo a capacidade de capturar padrões, dependências e relações semânticas complexas da linguagem natural \cite{GPTLearn}. Após o pré-treinamento, os modelos podem ser refinados e adaptados para tarefas específicas, como resposta a perguntas, sumarização de textos, suporte à programação, geração criativa de conteúdo e diálogo contextualizado \cite{openai2023gpt4,GPTtraining}. 

Ao longo de sua evolução, a série GPT passou por avanços significativos desde o GPT-1 até o GPT-5, cada versão trazendo aumentos expressivos na quantidade de parâmetros, na diversidade de dados de treinamento e na sofisticação de suas capacidades linguísticas.

No contexto deste trabalho, o ChatGPT se destaca como um dos principais referenciais para a avaliação de desempenho, devido a sua ampla utilização em diferentes domínios e a sua relevância acadêmica e prática. Sendo considerado como um marco no desenvolvimento de modelos de linguagem de grande porte e frequentemente utilizado como ponto de partida em pesquisas acadêmicas e \textit{benchmarks} internacionais de desempenho. Sua adoção em escala global e sua constante evolução o tornam um modelo representativo para comparações sistemáticas, servindo como parâmetro para análise do desempenho de outras arquiteturas contemporâneas de inteligência artificial \cite{GPTeducation}.

Para o nosso estudo, foi escolhido o GPT-4.1-mini devido ao fato de ele representar a proposta mais recente da OpenAI para um modelo leve, acessível e altamente otimizado. Lançado como parte da família GPT-4.1, o modelo mini prioriza rapidez, baixo custo por \textit{token} e alto grau de alinhamento, preservando características essenciais das versões mais robustas, como coerência, cobertura conceitual e estabilidade comportamental.

\subsection{Gemini}
O Gemini, desenvolvido pelo Google, foi lançado inicialmente em 2023 sob o nome Bard. O sistema passou por uma reformulação em 2024, quando a marca foi substituída por Gemini. A mudança não foi apenas nominal: refletiu a transição de um produto único para uma família completa de modelos, projetados para atender a diferentes níveis de complexidade e aplicações, afastando-se da interpretação limitada que o nome original poderia sugerir \cite{CMSWire}. Além disso, o Gemini se beneficia do ecossistema tecnológico do Google, que reúne uma infraestrutura altamente escalável e integrada, apoiada por serviços como o Google Cloud. Essa base consolidada contribui para maior confiabilidade, eficiência operacional e suporte robusto ao modelo, reforçando seu desempenho em aplicações práticas.

O funcionamento do Gemini segue a estrutura típica dos LLMs contemporâneos: pré-treinamento em larga escala, pós-treinamento orientado a alinhamento e segurança, geração de respostas condicionada ao \textit{prompt} e refinamento contínuo baseado em feedback humano. Apesar do alto desempenho observado, o modelo compartilha limitações inerentes à tecnologia atual, como possibilidade de gerar respostas imprecisas, interpretações excessivamente literais ou detalhamento além do necessário.

Entre suas características distintivas, destaca-se o suporte ampliado ao contexto, oferecendo capacidade de processamento de até 1 milhão de \textit{tokens} \cite{Zapier}. Essa extensão significativa permite ao Gemini manter coerência em interações longas e trabalhar com documentos extensos sem perda de informação, o que o diferencia de diversos outros modelos disponíveis comercialmente.

No nosso estudo escolhemos o \textit{Gemini 2.5 Flash}, por representar o modelo de menor latência e maior eficiência dentro da geração 2.5 do ecossistema Gemini. Como integrante da geração 2.5, ele incorpora avanços relevantes em interpretação estrutural de código, maior profundidade contextual e capacidade ampliada de manter coerência em respostas complexas.
