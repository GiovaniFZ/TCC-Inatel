\section{Modelos de IA avaliados}
\subsection{ChatGPT}
Um dos exemplos mais conhecidos de LLM é a série Generative Pre-trained Transformer (GPT), desenvolvida pela OpenAI. Os modelos são pré-treinados em grandes quantidades de dados de texto por meio de aprendizado não supervisionado e aprendem a identificar relacionamentos e padrões nos dados de linguagem. Uma vez pré-treinados, os modelos podem ser ajustados para tarefas como resposta a perguntas, criação de conteúdo, sumarização de texto e geração de código de software. \\
No entanto, o ChatGPT também apresenta vários tipos de riscos e implicações. A capacidade do ChatGPT de gerar respostas convincentes pode ser explorada por atores mal-intencionados para disseminar desinformação, lançar ataques de phishing ou até mesmo se passar por indivíduos \cite{GPT-SecurityRisks}.

\subsection{Gemini}
Outro exemplo de uma LLM que vem ganhando força é o Gemini, do Google. Ele foi inicialmente desenvolvido em 2023 pela Google com o nome de Bard. A mudança do nome ocorreu em 2024, pois a empresa criou não apenas um produto de IA, mas sim uma família de modelos que foram se aperfeiçoando com o passar do tempo. Dessa forma, o produto não transmitiria a ideia de que ele seria "apenas um poeta", mas sim algo muito maior. \cite{CMSWire} \\
O Gemini funciona da seguinte forma: Primeiro, o modelo é pré-treinado, passa por um processo de pós-treino, gera as respostas aos prompts e, finalmente, o feedback humano é analisado. Porém, assim como todos os modelos de IA, o Gemini também possui algumas limitações, especialmente no que diz respeito às respostas, pois, algumas vezes, elas serão falsos positivos ou falsos negativos, além do mais, podem ocorrer vieses ou aluncinações. Dessa forma, é válido utilizá-las com cautela. \cite{Google} \\
Apesar de parecidos, há algumas diferenças no Gemini em relação a outros modelos de IA. Uma das vantagens por exemplo é a presença de 1 milhão de tokens \cite{Zapier}, com isso, temos uma capacidade maior de fazer mais perguntas e respostas, sem perder o contexto.

\subsection{Grok}
O Grok é um assistente de inteligência artificial (IA) gratuito, integrado à plataforma X (antiga rede social Twitter). Foi lançado em novembro de 2023 pela xAI, startup fundada por Elon Musk, empresário e bilionário do setor de tecnologia, com o objetivo de competir diretamente com o ChatGPT \cite{TECNOBLOG}. \\
Utilizando técnicas de machine learning semelhantes às do ChatGPT, o Grok oferece funcionalidades como análise de dados em tempo real, criação de conteúdo, automação de fluxos de trabalho, verificação de informações e geração de previsões \cite{LATENODE}. Seu principal diferencial em relação aos modelos tradicionais, que dependem de dados históricos, está na capacidade de realizar pesquisas em tempo real, fornecendo respostas atualizadas com base nos dados da rede social X \cite{xAI}. \\
A xAI disponibiliza uma API que possibilita a desenvolvedores integrarem os modelos Grok em diferentes aplicações. Além da integração com a própria plataforma X, a empresa oferece o serviço Grok.com e aplicativos para dispositivos iOS e Android \cite{xAI}. \\ 
Quanto às interfaces, existem diferenças entre o uso no X e na versão Web (Grok.com). No X, é permitido anexar arquivos no modo Think, mas não há possibilidade de alternar entre diferentes modelos. Já na versão Web, não há suporte para anexos, porém o usuário pode alternar livremente entre os modos disponíveis \cite{LATENODE}. \\
O pré-treinamento do modelo foi realizado a partir de uma ampla variedade de informações e conjuntos de dados públicos, revisados e selecionados por avaliadores humanos. Sua versão mais recente é o Grok 3, que apresenta como principais vantagens a integração direta com o X e a disponibilização de diferentes modos de uso: Think, voltado para questões lógicas; DeepSearch, especializado em buscas de informações gerais e atualizadas na web; Big Brain Mode, que utiliza maior poder computacional para tarefas complexas, sendo ativado automaticamente; e Grok 3 Mini, versão otimizada para maior velocidade e menor uso de recursos \cite{xAI, DASCIA}. \\
A principal desvantagem do Grok está no uso de tweets como fonte de dados, o que pode potencializar a propagação de desinformação \cite{TECNOBLOG}. \\

\subsection{DeepSeek}
O DeepSeek é um grande modelo de linguagem (LLM) desenvolvido pela empresa chinesa DeepSeek AI, fundada em 2023 e dedicada ao avanço da inteligência artificial geral (AGI).\cite{DeepSeekHuggingFace} Diferente de outros LLMs, o DeepSeek destaca-se pela disponibilização de uma família de LLMs voltados para tarefas técnicas, com ênfase em eficiência de inferência e raciocínio lógico \cite{BentoMLDeepSeek}.

Entre os principais lançamentos estão o DeepSeek-V3 e o DeepSeek-R1. O DeepSeek-V3 utiliza uma arquitetura de grande escala baseada em Mixture of Experts (MoE), com 671 bilhões de parâmetros no total, mas ativando apenas 37 bilhões por token, o que reduz significativamente os custos de inferência sem comprometer o desempenho. Essa eficiência é alcançada por meio de técnicas como Multi-head Latent Attention (MLA), otimizações de balanceamento de carga entre especialistas e um objetivo de treinamento com predição multi-token, que melhora a coerência em sequências longas \cite{DeepSeekV3TechReport, DeepSeekV3HuggingFace}.

O DeepSeek-R1, por sua vez, foi projetado com foco em tarefas que exigem raciocínio passo a passo, como matemática avançada, programação e análise financeira. Ele apresenta desempenho competitivo em benchmarks de lógica e raciocínio, sendo comparável a modelos líderes como o GPT-4o da OpenAI. Além disso, a disponibilização de variantes open-source e repositórios associados favorece a reprodutibilidade e o estudo comparativo por pesquisadores e desenvolvedores \cite{DeepSeekR1Benchmark}
.
Apesar das qualidades de desempenho, análises recentes destacam preocupações relacionadas à segurança do DeepSeek. Estudos indicam que o modelo pode exibir alucinações em tarefas de percepção visual ou em cenários sensíveis, como aplicações clínicas e interações humanas diretas, o que evidencia a necessidade de estratégias de mitigação, alinhamento e filtragem de conteúdo antes da integração em sistemas críticos \cite{DeepSeekSafetyAnalysis}.

